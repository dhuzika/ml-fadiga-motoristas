{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepara√ß√£o dos Dados UTA-RLDD\n",
    "\n",
    "## Resumo\n",
    "Este notebook processa o dataset UTA-RLDD para detec√ß√£o de fadiga, extraindo caracter√≠sticas faciais para treinamento de modelos de deep learning.\n",
    "\n",
    "### Caracter√≠sticas extra√≠das:\n",
    "- **PERCLOS**: Percentual de fechamento das p√°lpebras\n",
    "- **MAR**: Propor√ß√£o de abertura da boca (detecta bocejos)\n",
    "- **BLINK_RATE**: Taxa de piscadas por minuto\n",
    "- **HEAD_STABILITY**: Estabilidade da postura da cabe√ßa\n",
    "\n",
    "### Resultados esperados:\n",
    "- Sequ√™ncias de 90 frames (3 segundos)\n",
    "- ~32k sequ√™ncias de 48 participantes\n",
    "- Precis√£o esperada: 75-85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar depend√™ncias necess√°rias\n",
    "!pip install --upgrade kagglehub\n",
    "!pip install opencv-python mediapipe scikit-learn pandas numpy matplotlib seaborn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas\n",
    "import kagglehub\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, deque\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Par√¢metros do processamento\n",
    "TARGET_FPS = 30\n",
    "SEQUENCE_LENGTH = 90  # 3 segundos\n",
    "OVERLAP_RATIO = 0.67  # 67% de sobreposi√ß√£o\n",
    "MIN_FACE_CONFIDENCE = 0.7\n",
    "\n",
    "print(f\"üöÄ Sistema de extra√ß√£o de caracter√≠sticas inicializado\")\n",
    "print(f\"üìä Sequ√™ncias: {SEQUENCE_LENGTH} frames ({SEQUENCE_LENGTH/TARGET_FPS:.1f}s)\")\n",
    "print(f\"üîÑ Sobreposi√ß√£o: {OVERLAP_RATIO*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se o dataset j√° existe\n",
    "dataset_path = Path(\"/home/zhizhunu/.cache/kagglehub/datasets/rishab260/uta-reallife-drowsiness-dataset/versions/1\")\n",
    "\n",
    "if dataset_path.exists():\n",
    "    print(f\"‚úÖ Dataset j√° dispon√≠vel em: {dataset_path}\")\n",
    "else:\n",
    "    print(\"üì• Fazendo download do dataset UTA-RLDD...\")\n",
    "    try:\n",
    "        dataset_path = kagglehub.dataset_download(\"rishab260/uta-reallife-drowsiness-dataset\")\n",
    "        dataset_path = Path(dataset_path)\n",
    "        print(f\"‚úÖ Dataset baixado para: {dataset_path}\")\n",
    "    except AttributeError:\n",
    "        print(\"‚ùå Erro: Atualize o kagglehub com: pip install --upgrade kagglehub\")\n",
    "        raise\n",
    "\n",
    "# Verificar estrutura do dataset\n",
    "video_files = list(dataset_path.rglob(\"*.mp4\")) + list(dataset_path.rglob(\"*.mov\")) + list(dataset_path.rglob(\"*.m4v\"))\n",
    "print(f\"üìÅ Encontrados {len(video_files)} arquivos de v√≠deo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extrator de Caracter√≠sticas de Fadiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtratorCaracteristicasFadiga:\n",
    "    \"\"\"\n",
    "    Extrai caracter√≠sticas de fadiga de v√≠deos usando MediaPipe\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.face_mesh = mp_face_mesh.FaceMesh(\n",
    "            static_image_mode=False,\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=MIN_FACE_CONFIDENCE,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        \n",
    "        # Thresholds calibrados para detec√ß√£o\n",
    "        self.EAR_FECHADO_THRESHOLD = 0.25\n",
    "        self.EAR_PISCADA_THRESHOLD = 0.22\n",
    "        self.MAR_BOCEJO_THRESHOLD = 0.6\n",
    "        self.JANELA_PERCLOS_SEC = 60\n",
    "        self.JANELA_PISCADA_SEC = 30\n",
    "        \n",
    "        # √çndices dos landmarks do MediaPipe\n",
    "        self.OLHO_ESQUERDO = [362, 385, 387, 263, 373, 380]\n",
    "        self.OLHO_DIREITO = [33, 160, 158, 133, 153, 144]\n",
    "        self.BOCA_EXTERNA = [61, 84, 17, 314, 405, 320, 375, 321]\n",
    "        self.PONTOS_CABECA = [1, 2, 5, 4, 6, 168, 8, 9, 10, 151]\n",
    "        \n",
    "        self.resetar_buffers()\n",
    "    \n",
    "    def resetar_buffers(self):\n",
    "        \"\"\"Reseta buffers temporais para novo v√≠deo\"\"\"\n",
    "        buffer_size = self.JANELA_PERCLOS_SEC * TARGET_FPS\n",
    "        self.buffer_ear = deque(maxlen=buffer_size)\n",
    "        self.buffer_mar = deque(maxlen=self.JANELA_PISCADA_SEC * TARGET_FPS)\n",
    "        self.posicoes_cabeca = deque(maxlen=TARGET_FPS * 5)\n",
    "        self.timestamps_piscadas = deque(maxlen=100)\n",
    "        self.timestamps_frames = deque(maxlen=buffer_size)\n",
    "        \n",
    "        # Controle de estado\n",
    "        self.ultimo_ear = None\n",
    "        self.estado_piscada = False\n",
    "        self.frames_fechados_consecutivos = 0\n",
    "        self.contador_frames = 0\n",
    "    \n",
    "    def calcular_ear(self, landmarks_olho):\n",
    "        \"\"\"Calcula Eye Aspect Ratio\"\"\"\n",
    "        # Dist√¢ncias verticais\n",
    "        v1 = euclidean(landmarks_olho[1], landmarks_olho[5])\n",
    "        v2 = euclidean(landmarks_olho[2], landmarks_olho[4])\n",
    "        # Dist√¢ncia horizontal\n",
    "        h = euclidean(landmarks_olho[0], landmarks_olho[3])\n",
    "        \n",
    "        if h < 1e-6:\n",
    "            return 0.0\n",
    "        \n",
    "        ear = (v1 + v2) / (2.0 * h)\n",
    "        return max(0.0, min(1.0, ear))\n",
    "    \n",
    "    def calcular_mar(self, landmarks_boca):\n",
    "        \"\"\"Calcula Mouth Aspect Ratio para detec√ß√£o de bocejos\"\"\"\n",
    "        # Dist√¢ncias verticais em diferentes posi√ß√µes da boca\n",
    "        v1 = euclidean(landmarks_boca[2], landmarks_boca[6])\n",
    "        v2 = euclidean(landmarks_boca[3], landmarks_boca[7])\n",
    "        # Dist√¢ncia horizontal\n",
    "        h = euclidean(landmarks_boca[0], landmarks_boca[1])\n",
    "        \n",
    "        if h < 1e-6:\n",
    "            return 0.0\n",
    "            \n",
    "        mar = (v1 + v2) / (2.0 * h)\n",
    "        return max(0.0, min(2.0, mar))\n",
    "    \n",
    "    def detectar_piscada(self, ear_atual, timestamp):\n",
    "        \"\"\"Detecta piscadas com valida√ß√£o temporal\"\"\"\n",
    "        piscada_detectada = False\n",
    "        \n",
    "        if self.ultimo_ear is not None:\n",
    "            # Transi√ß√£o de fechamento do olho\n",
    "            if (self.ultimo_ear > self.EAR_PISCADA_THRESHOLD and \n",
    "                ear_atual <= self.EAR_PISCADA_THRESHOLD):\n",
    "                self.frames_fechados_consecutivos = 1\n",
    "                self.estado_piscada = True\n",
    "            \n",
    "            # Olho fechado (acumula frames fechados)\n",
    "            elif ear_atual <= self.EAR_PISCADA_THRESHOLD and self.estado_piscada:\n",
    "                self.frames_fechados_consecutivos += 1\n",
    "            \n",
    "            # Transi√ß√£o de abertura (piscada completa)\n",
    "            elif (self.ultimo_ear <= self.EAR_PISCADA_THRESHOLD and \n",
    "                  ear_atual > self.EAR_PISCADA_THRESHOLD and \n",
    "                  self.estado_piscada and \n",
    "                  2 <= self.frames_fechados_consecutivos <= 15):\n",
    "                piscada_detectada = True\n",
    "                self.timestamps_piscadas.append(timestamp)\n",
    "                self.estado_piscada = False\n",
    "                self.frames_fechados_consecutivos = 0\n",
    "        \n",
    "        self.ultimo_ear = ear_atual\n",
    "        return piscada_detectada\n",
    "    \n",
    "    def calcular_perclos(self, timestamp):\n",
    "        \"\"\"Calcula PERCLOS com janela temporal adequada\"\"\"\n",
    "        if len(self.buffer_ear) < 10:\n",
    "            return 0.0\n",
    "        \n",
    "        # Usar dados recentes para c√°lculo do PERCLOS\n",
    "        ears_recentes = list(self.buffer_ear)[-min(len(self.buffer_ear), \n",
    "                                                    TARGET_FPS * 30):]\n",
    "        \n",
    "        frames_fechados = sum(1 for ear in ears_recentes if ear <= self.EAR_FECHADO_THRESHOLD)\n",
    "        perclos = (frames_fechados / len(ears_recentes)) * 100\n",
    "        \n",
    "        return min(100.0, perclos)\n",
    "    \n",
    "    def calcular_taxa_piscadas(self, timestamp):\n",
    "        \"\"\"Calcula piscadas por minuto com valida√ß√£o temporal\"\"\"\n",
    "        if len(self.timestamps_piscadas) < 1:\n",
    "            return 0.0\n",
    "        \n",
    "        # Contar piscadas na janela recente\n",
    "        inicio_janela = timestamp - self.JANELA_PISCADA_SEC\n",
    "        piscadas_recentes = [t for t in self.timestamps_piscadas if t >= inicio_janela]\n",
    "        \n",
    "        if len(piscadas_recentes) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Converter para piscadas por minuto\n",
    "        tempo_decorrido = min(self.JANELA_PISCADA_SEC, \n",
    "                             max(timestamp - self.timestamps_piscadas[0], 1.0))\n",
    "        if tempo_decorrido < 1.0:\n",
    "            return 0.0\n",
    "        \n",
    "        piscadas_por_minuto = (len(piscadas_recentes) / tempo_decorrido) * 60\n",
    "        return min(60.0, piscadas_por_minuto)\n",
    "    \n",
    "    def calcular_estabilidade_cabeca(self, landmarks, timestamp):\n",
    "        \"\"\"Calcula estabilidade do movimento da cabe√ßa\"\"\"\n",
    "        pontos_cabeca = [landmarks[i] for i in self.PONTOS_CABECA]\n",
    "        \n",
    "        # Calcular centro da cabe√ßa\n",
    "        centro_cabeca = np.mean(pontos_cabeca, axis=0)[:2]\n",
    "        self.posicoes_cabeca.append((centro_cabeca, timestamp))\n",
    "        \n",
    "        if len(self.posicoes_cabeca) < TARGET_FPS:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calcular movimento na janela recente\n",
    "        posicoes_recentes = [pos[0] for pos in self.posicoes_cabeca]\n",
    "        array_posicoes = np.array(posicoes_recentes)\n",
    "        \n",
    "        # Calcular estabilidade como inverso da vari√¢ncia do movimento\n",
    "        variancia_movimento = np.var(array_posicoes, axis=0).sum()\n",
    "        estabilidade = 1.0 / (1.0 + variancia_movimento * 1000)\n",
    "        \n",
    "        return estabilidade\n",
    "    \n",
    "    def extrair_caracteristicas_frame(self, frame, timestamp):\n",
    "        \"\"\"Extrai todas as caracter√≠sticas de um √∫nico frame\"\"\"\n",
    "        self.contador_frames += 1\n",
    "        \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        resultados = self.face_mesh.process(frame_rgb)\n",
    "        \n",
    "        if not resultados.multi_face_landmarks:\n",
    "            return None\n",
    "        \n",
    "        landmarks = resultados.multi_face_landmarks[0]\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # Converter para coordenadas em pixels\n",
    "        landmarks_px = [(lm.x * w, lm.y * h) for lm in landmarks.landmark]\n",
    "        \n",
    "        # Calcular EAR\n",
    "        olho_esquerdo = [landmarks_px[i] for i in self.OLHO_ESQUERDO]\n",
    "        olho_direito = [landmarks_px[i] for i in self.OLHO_DIREITO]\n",
    "        ear_esquerdo = self.calcular_ear(olho_esquerdo)\n",
    "        ear_direito = self.calcular_ear(olho_direito)\n",
    "        ear_medio = (ear_esquerdo + ear_direito) / 2.0\n",
    "        \n",
    "        # Armazenar EAR para c√°lculos temporais\n",
    "        self.buffer_ear.append(ear_medio)\n",
    "        self.timestamps_frames.append(timestamp)\n",
    "        \n",
    "        # Calcular caracter√≠sticas\n",
    "        piscada_detectada = self.detectar_piscada(ear_medio, timestamp)\n",
    "        perclos = self.calcular_perclos(timestamp)\n",
    "        taxa_piscadas = self.calcular_taxa_piscadas(timestamp)\n",
    "        \n",
    "        # C√°lculo do MAR\n",
    "        landmarks_boca = [landmarks_px[i] for i in self.BOCA_EXTERNA]\n",
    "        mar = self.calcular_mar(landmarks_boca)\n",
    "        self.buffer_mar.append(mar)\n",
    "        \n",
    "        # Estabilidade da cabe√ßa\n",
    "        estabilidade_cabeca = self.calcular_estabilidade_cabeca(landmarks_px, timestamp)\n",
    "        \n",
    "        return {\n",
    "            'PERCLOS': perclos,\n",
    "            'MAR': mar,\n",
    "            'BLINK_RATE': taxa_piscadas,\n",
    "            'HEAD_STABILITY': estabilidade_cabeca,\n",
    "            'timestamp': timestamp,\n",
    "            'frame_count': self.contador_frames,\n",
    "            'blink_detected': piscada_detectada,\n",
    "            'EAR': ear_medio\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Extrator de caracter√≠sticas criado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An√°lise da Estrutura do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_estrutura_dataset(dataset_path):\n",
    "    \"\"\"Analisa a estrutura do UTA-RLDD e cria mapeamento dos v√≠deos\"\"\"\n",
    "    video_files = []\n",
    "    extensoes = ['.mp4', '.mov', '.m4v', '.avi']\n",
    "    \n",
    "    for ext in extensoes:\n",
    "        video_files.extend(list(dataset_path.rglob(f\"*{ext}\")))\n",
    "        video_files.extend(list(dataset_path.rglob(f\"*{ext.upper()}\")))\n",
    "    \n",
    "    print(f\"Encontrados {len(video_files)} arquivos de v√≠deo\")\n",
    "    \n",
    "    # Criar mapeamento do dataset\n",
    "    dados_videos = []\n",
    "    \n",
    "    for caminho_video in video_files:\n",
    "        nome_arquivo = caminho_video.name.lower()\n",
    "        \n",
    "        # Extrair label do nome do arquivo\n",
    "        if nome_arquivo.startswith('0.'):\n",
    "            label, estado = 0, 'Alert'\n",
    "        elif nome_arquivo.startswith('5.'):\n",
    "            label, estado = 5, 'Low_Vigilant'\n",
    "        elif nome_arquivo.startswith('10') or '10.' in nome_arquivo or '10_' in nome_arquivo:\n",
    "            label, estado = 10, 'Drowsy'\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # Extrair ID do participante do caminho\n",
    "        partes_caminho = str(caminho_video).split('/')\n",
    "        id_participante = 'desconhecido'\n",
    "        \n",
    "        for parte in reversed(partes_caminho):\n",
    "            if re.match(r'^\\d{1,2}$', parte):\n",
    "                id_participante = f\"{int(parte):02d}\"\n",
    "                break\n",
    "        \n",
    "        if id_participante != 'desconhecido':\n",
    "            dados_videos.append({\n",
    "                'video_path': str(caminho_video),\n",
    "                'filename': caminho_video.name,\n",
    "                'subject_id': id_participante,\n",
    "                'label': label,\n",
    "                'state': estado\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(dados_videos)\n",
    "    \n",
    "    print(f\"\\nüìä An√°lise do Dataset:\")\n",
    "    print(f\"V√≠deos v√°lidos: {len(df)}\")\n",
    "    print(f\"Participantes: {df['subject_id'].nunique()}\")\n",
    "    print(f\"\\nDistribui√ß√£o de labels:\")\n",
    "    print(df['state'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Analisar dataset\n",
    "df_videos = analisar_estrutura_dataset(dataset_path)\n",
    "print(f\"\\n‚úÖ Encontrados {len(df_videos)} v√≠deos v√°lidos de {df_videos['subject_id'].nunique()} participantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Processamento de V√≠deos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_video(caminho_video, extrator, duracao_max_sec=300, \n",
    "                   threshold_qualidade=0.8, pular_frames=1):\n",
    "    \"\"\"Processa um v√≠deo extraindo caracter√≠sticas com controle de qualidade\"\"\"\n",
    "    cap = cv2.VideoCapture(caminho_video)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        return [], f\"N√£o foi poss√≠vel abrir o v√≠deo: {caminho_video}\"\n",
    "    \n",
    "    # Propriedades do v√≠deo\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duracao = total_frames / fps if fps > 0 else 0\n",
    "    \n",
    "    max_frames = min(total_frames, int(duracao_max_sec * fps)) if fps > 0 else total_frames\n",
    "    fps_efetivo = fps / pular_frames if pular_frames > 1 else fps\n",
    "    \n",
    "    print(f\"  üìπ {Path(caminho_video).name}: {fps:.1f}fps‚Üí{fps_efetivo:.1f}fps, {duracao:.1f}s\")\n",
    "    \n",
    "    # Resetar extrator\n",
    "    extrator.resetar_buffers()\n",
    "    \n",
    "    lista_caracteristicas = []\n",
    "    contador_frames = 0\n",
    "    contador_processados = 0\n",
    "    falhas_deteccao = 0\n",
    "    \n",
    "    while contador_frames < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Pular frames para acelerar processamento\n",
    "        if contador_frames % pular_frames == 0:\n",
    "            timestamp = contador_frames / fps if fps > 0 else contador_frames / TARGET_FPS\n",
    "            \n",
    "            # Redimensionar para processamento consistente\n",
    "            height, width = frame.shape[:2]\n",
    "            if width > 480:\n",
    "                scale = 480 / width\n",
    "                new_width, new_height = 480, int(height * scale)\n",
    "                frame = cv2.resize(frame, (new_width, new_height))\n",
    "            \n",
    "            # Extrair caracter√≠sticas\n",
    "            caracteristicas = extrator.extrair_caracteristicas_frame(frame, timestamp)\n",
    "            \n",
    "            if caracteristicas is not None:\n",
    "                caracteristicas['frame_number'] = contador_frames\n",
    "                lista_caracteristicas.append(caracteristicas)\n",
    "            else:\n",
    "                falhas_deteccao += 1\n",
    "            \n",
    "            contador_processados += 1\n",
    "            \n",
    "            # Atualiza√ß√£o de progresso\n",
    "            if contador_processados % 200 == 0:\n",
    "                progresso = (contador_frames / max_frames) * 100\n",
    "                taxa_sucesso = len(lista_caracteristicas) / contador_processados\n",
    "                print(f\"    Progresso: {progresso:.1f}% ({len(lista_caracteristicas)} caracter√≠sticas, {taxa_sucesso:.1%} sucesso)\")\n",
    "        \n",
    "        contador_frames += 1\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Avalia√ß√£o da qualidade\n",
    "    taxa_sucesso = len(lista_caracteristicas) / contador_processados if contador_processados > 0 else 0\n",
    "    \n",
    "    if taxa_sucesso < threshold_qualidade:\n",
    "        return [], f\"V√≠deo de baixa qualidade: {taxa_sucesso:.1%} taxa de detec√ß√£o\"\n",
    "    \n",
    "    print(f\"  ‚úÖ Processados {len(lista_caracteristicas)} frames ({taxa_sucesso:.1%} taxa de sucesso)\")\n",
    "    return lista_caracteristicas, None\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de processamento de v√≠deo prontas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Processamento de Todos os V√≠deos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Configura√ß√µes de processamento\n",
    "MODO_RAPIDO = False\n",
    "MAX_VIDEOS = len(df_videos)\n",
    "DURACAO_MAX = 240  # 4 minutos por v√≠deo\n",
    "THRESHOLD_QUALIDADE = 0.7\n",
    "PULAR_FRAMES = 1  # Processar todos os frames\n",
    "\n",
    "def processar_video_seguro(info_video):\n",
    "    \"\"\"Processa um √∫nico v√≠deo com tratamento de erros\"\"\"\n",
    "    idx, row = info_video\n",
    "    \n",
    "    # Criar extrator local\n",
    "    extrator_local = ExtratorCaracteristicasFadiga()\n",
    "    \n",
    "    try:\n",
    "        lista_caracteristicas, erro = processar_video(\n",
    "            row['video_path'], \n",
    "            extrator_local,\n",
    "            duracao_max_sec=DURACAO_MAX,\n",
    "            threshold_qualidade=THRESHOLD_QUALIDADE,\n",
    "            pular_frames=PULAR_FRAMES\n",
    "        )\n",
    "        \n",
    "        if erro:\n",
    "            return {'status': 'erro', 'idx': idx, 'error': erro, 'row': row}\n",
    "        \n",
    "        if len(lista_caracteristicas) >= SEQUENCE_LENGTH:\n",
    "            return {\n",
    "                'status': 'sucesso',\n",
    "                'idx': idx,\n",
    "                'video_path': row['video_path'],\n",
    "                'filename': row['filename'],\n",
    "                'subject_id': row['subject_id'],\n",
    "                'label': row['label'],\n",
    "                'state': row['state'],\n",
    "                'features': lista_caracteristicas,\n",
    "                'n_frames': len(lista_caracteristicas)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'status': 'insuficiente',\n",
    "                'idx': idx,\n",
    "                'error': f'Frames insuficientes: {len(lista_caracteristicas)}',\n",
    "                'row': row\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {'status': 'excecao', 'idx': idx, 'error': str(e), 'row': row}\n",
    "\n",
    "# Processar v√≠deos\n",
    "videos_processados = []\n",
    "videos_falharam = []\n",
    "\n",
    "print(f\"üöÄ PROCESSAMENTO COMPLETO DO DATASET\")\n",
    "print(f\"üìä Processando: {MAX_VIDEOS}/{len(df_videos)} v√≠deos\")\n",
    "print(f\"‚ö° Configura√ß√µes: {DURACAO_MAX}s max, qualidade {THRESHOLD_QUALIDADE:.1f}\")\n",
    "\n",
    "# Mostrar thresholds calibrados\n",
    "extrator_teste = ExtratorCaracteristicasFadiga()\n",
    "print(f\"üîß Thresholds calibrados:\")\n",
    "print(f\"   EAR_FECHADO: {extrator_teste.EAR_FECHADO_THRESHOLD}\")\n",
    "print(f\"   EAR_PISCADA: {extrator_teste.EAR_PISCADA_THRESHOLD}\")\n",
    "\n",
    "print(f\"‚è±Ô∏è  Tempo estimado: {MAX_VIDEOS * 0.5 / 60:.0f}-{MAX_VIDEOS * 2 / 60:.0f} minutos\")\n",
    "\n",
    "tempo_inicio = time.time()\n",
    "\n",
    "# Processar v√≠deos sequencialmente\n",
    "for idx, (video_idx, row) in enumerate(df_videos.iterrows()):\n",
    "    print(f\"\\nüé¨ Processando v√≠deo {idx+1}/{MAX_VIDEOS}: {row['subject_id']} {row['state']} ({row['filename']})\")\n",
    "    \n",
    "    resultado = processar_video_seguro((video_idx, row))\n",
    "    \n",
    "    if resultado['status'] == 'sucesso':\n",
    "        videos_processados.append({\n",
    "            'video_path': resultado['video_path'],\n",
    "            'filename': resultado['filename'],\n",
    "            'subject_id': resultado['subject_id'],\n",
    "            'label': resultado['label'],\n",
    "            'state': resultado['state'],\n",
    "            'features': resultado['features'],\n",
    "            'n_frames': resultado['n_frames']\n",
    "        })\n",
    "        \n",
    "        # Verifica√ß√£o r√°pida das caracter√≠sticas nos primeiros v√≠deos\n",
    "        caracteristicas = resultado['features']\n",
    "        perclos_medio = np.mean([f['PERCLOS'] for f in caracteristicas])\n",
    "        taxa_piscadas_medio = np.mean([f['BLINK_RATE'] for f in caracteristicas])\n",
    "        \n",
    "        print(f\"  ‚úÖ SUCESSO: {resultado['n_frames']} frames extra√≠dos\")\n",
    "        if idx < 5:  # Mostrar estat√≠sticas para os primeiros 5\n",
    "            print(f\"     PERCLOS: Œº={perclos_medio:.1f}%\")\n",
    "            print(f\"     BLINK_RATE: Œº={taxa_piscadas_medio:.1f} bpm\")\n",
    "    else:\n",
    "        videos_falharam.append({\n",
    "            'video_path': resultado['row']['video_path'],\n",
    "            'error': resultado['error']\n",
    "        })\n",
    "        print(f\"  ‚ùå FALHOU: {resultado['error']}\")\n",
    "    \n",
    "    # Atualiza√ß√£o de progresso a cada 10 v√≠deos\n",
    "    if (idx + 1) % 10 == 0:\n",
    "        tempo_decorrido = time.time() - tempo_inicio\n",
    "        tempo_restante = (MAX_VIDEOS - idx - 1) * (tempo_decorrido / (idx + 1))\n",
    "        print(f\"\\nüìä Progresso: {idx+1}/{MAX_VIDEOS} ({(idx+1)/MAX_VIDEOS*100:.1f}%)\")\n",
    "        print(f\"‚è±Ô∏è  Decorrido: {tempo_decorrido/60:.1f}min, Restante: ~{tempo_restante/60:.1f}min\")\n",
    "        print(f\"‚úÖ Sucesso: {len(videos_processados)}, ‚ùå Falhas: {len(videos_falharam)}\")\n",
    "\n",
    "tempo_total = time.time() - tempo_inicio\n",
    "print(f\"\\n=== Processamento Completo ===\")\n",
    "print(f\"‚è±Ô∏è  Tempo total: {tempo_total:.1f} segundos ({tempo_total/60:.1f} minutos)\")\n",
    "print(f\"‚úÖ Processados com sucesso: {len(videos_processados)} v√≠deos\")\n",
    "print(f\"‚ùå Falharam: {len(videos_falharam)} v√≠deos\")\n",
    "if len(videos_processados) + len(videos_falharam) > 0:\n",
    "    print(f\"üìà Taxa de sucesso: {len(videos_processados)/(len(videos_processados)+len(videos_falharam))*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. An√°lise da Qualidade das Caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(videos_processados) > 0:\n",
    "    print(\"üîç Analisando qualidade das caracter√≠sticas...\")\n",
    "    \n",
    "    # Coletar todas as caracter√≠sticas para an√°lise\n",
    "    todas_caracteristicas = []\n",
    "    todos_labels = []\n",
    "    todos_estados = []\n",
    "    todos_participantes = []\n",
    "    \n",
    "    for dados_video in videos_processados:\n",
    "        for caracteristicas in dados_video['features']:\n",
    "            todas_caracteristicas.append([\n",
    "                caracteristicas['PERCLOS'],\n",
    "                caracteristicas['MAR'],\n",
    "                caracteristicas['BLINK_RATE'],\n",
    "                caracteristicas['HEAD_STABILITY']\n",
    "            ])\n",
    "            todos_labels.append(dados_video['label'])\n",
    "            todos_estados.append(dados_video['state'])\n",
    "            todos_participantes.append(dados_video['subject_id'])\n",
    "    \n",
    "    # Criar DataFrame para an√°lise\n",
    "    nomes_caracteristicas = ['PERCLOS', 'MAR', 'BLINK_RATE', 'HEAD_STABILITY']\n",
    "    df_caracteristicas = pd.DataFrame(todas_caracteristicas, columns=nomes_caracteristicas)\n",
    "    df_caracteristicas['Label'] = todos_labels\n",
    "    df_caracteristicas['State'] = todos_estados\n",
    "    df_caracteristicas['Subject'] = todos_participantes\n",
    "    \n",
    "    print(f\"\\nüìä Estat√≠sticas das Caracter√≠sticas por Estado:\")\n",
    "    stats_por_estado = df_caracteristicas.groupby('State')[nomes_caracteristicas].agg(['mean', 'std'])\n",
    "    print(stats_por_estado.round(3))\n",
    "    \n",
    "    # Verificar poder discriminativo\n",
    "    print(f\"\\nüéØ Poder Discriminativo (Alert vs Drowsy):\")\n",
    "    dados_alert = df_caracteristicas[df_caracteristicas['State'] == 'Alert']\n",
    "    dados_drowsy = df_caracteristicas[df_caracteristicas['State'] == 'Drowsy']\n",
    "    \n",
    "    for caracteristica in nomes_caracteristicas:\n",
    "        media_alert = dados_alert[caracteristica].mean()\n",
    "        media_drowsy = dados_drowsy[caracteristica].mean()\n",
    "        std_combinado = np.sqrt((dados_alert[caracteristica].var() + dados_drowsy[caracteristica].var()) / 2)\n",
    "        tamanho_efeito = abs(media_drowsy - media_alert) / std_combinado if std_combinado > 0 else 0\n",
    "        \n",
    "        print(f\"  {caracteristica:15}: {tamanho_efeito:.3f} (Alert: {media_alert:.2f}, Drowsy: {media_drowsy:.2f})\")\n",
    "        \n",
    "        if tamanho_efeito > 0.8:\n",
    "            print(f\"    ‚úÖ Efeito grande - altamente discriminativo\")\n",
    "        elif tamanho_efeito > 0.5:\n",
    "            print(f\"    ‚úÖ Efeito m√©dio - boa discrimina√ß√£o\")\n",
    "        elif tamanho_efeito > 0.2:\n",
    "            print(f\"    ‚ö†Ô∏è  Efeito pequeno - discrimina√ß√£o limitada\")\n",
    "        else:\n",
    "            print(f\"    ‚ùå Efeito muito pequeno - discrimina√ß√£o pobre\")\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Verifica√ß√£o de Varia√ß√£o Temporal:\")\n",
    "    print(f\"Total de frames analisados: {len(df_caracteristicas):,}\")\n",
    "    print(f\"Total de participantes: {df_caracteristicas['Subject'].nunique()}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Nenhum v√≠deo processado dispon√≠vel para an√°lise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cria√ß√£o de Sequ√™ncias Temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_sequencias_temporais(videos_processados, tamanho_sequencia=SEQUENCE_LENGTH, \n",
    "                              razao_sobreposicao=OVERLAP_RATIO):\n",
    "    \"\"\"Cria sequ√™ncias temporais com labeling real√≠stico\"\"\"\n",
    "    todas_sequencias = []\n",
    "    todos_labels = []\n",
    "    todos_participantes = []\n",
    "    todas_infos_video = []\n",
    "    \n",
    "    nomes_caracteristicas = ['PERCLOS', 'MAR', 'BLINK_RATE', 'HEAD_STABILITY']\n",
    "    passo = max(1, int(tamanho_sequencia * (1 - razao_sobreposicao)))\n",
    "    \n",
    "    print(f\"Criando sequ√™ncias: comprimento={tamanho_sequencia}, passo={passo} ({razao_sobreposicao*100:.0f}% sobreposi√ß√£o)\")\n",
    "    \n",
    "    for dados_video in videos_processados:\n",
    "        lista_caracteristicas = dados_video['features']\n",
    "        \n",
    "        if len(lista_caracteristicas) < tamanho_sequencia:\n",
    "            continue\n",
    "        \n",
    "        # Converter para array\n",
    "        array_caracteristicas = np.array([\n",
    "            [f[nome] for nome in nomes_caracteristicas] \n",
    "            for f in lista_caracteristicas\n",
    "        ])\n",
    "        \n",
    "        # Criar sequ√™ncias com sobreposi√ß√£o\n",
    "        sequencias_video = []\n",
    "        for i in range(0, len(array_caracteristicas) - tamanho_sequencia + 1, passo):\n",
    "            sequencia = array_caracteristicas[i:i + tamanho_sequencia]\n",
    "            \n",
    "            # Verifica√ß√£o de qualidade: garantir varia√ß√£o temporal\n",
    "            stds_temporais = np.std(sequencia, axis=0)\n",
    "            if np.any(stds_temporais > 0.001):\n",
    "                sequencias_video.append(sequencia)\n",
    "        \n",
    "        if len(sequencias_video) > 0:\n",
    "            todas_sequencias.extend(sequencias_video)\n",
    "            todos_labels.extend([dados_video['label']] * len(sequencias_video))\n",
    "            todos_participantes.extend([dados_video['subject_id']] * len(sequencias_video))\n",
    "            todas_infos_video.extend([{\n",
    "                'filename': dados_video['filename'],\n",
    "                'state': dados_video['state']\n",
    "            }] * len(sequencias_video))\n",
    "        \n",
    "        print(f\"  {dados_video['subject_id']} {dados_video['state']}: {len(sequencias_video)} sequ√™ncias\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Criadas {len(todas_sequencias)} sequ√™ncias no total\")\n",
    "    \n",
    "    return (\n",
    "        np.array(todas_sequencias),\n",
    "        np.array(todos_labels),\n",
    "        np.array(todos_participantes),\n",
    "        todas_infos_video\n",
    "    )\n",
    "\n",
    "if len(videos_processados) > 0:\n",
    "    # Criar sequ√™ncias\n",
    "    X_raw, y, participantes, info_videos = criar_sequencias_temporais(videos_processados)\n",
    "    \n",
    "    print(f\"\\nüìä Resumo do Dataset de Sequ√™ncias:\")\n",
    "    print(f\"Formato: {X_raw.shape} (amostras, passos_tempo, caracter√≠sticas)\")\n",
    "    print(f\"Labels: {len(np.unique(y))} classes\")\n",
    "    print(f\"Participantes: {len(np.unique(participantes))}\")\n",
    "    \n",
    "    # Distribui√ß√£o de classes\n",
    "    labels_unicos, contagens = np.unique(y, return_counts=True)\n",
    "    print(f\"\\nDistribui√ß√£o de classes:\")\n",
    "    for label, contagem in zip(labels_unicos, contagens):\n",
    "        nome_classe = {0: 'Alert', 5: 'Low_Vigilant', 10: 'Drowsy'}.get(label, f'Classe_{label}')\n",
    "        print(f\"  {nome_classe} ({label}): {contagem:,} sequ√™ncias ({contagem/len(y)*100:.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Nenhum v√≠deo processado dispon√≠vel para cria√ß√£o de sequ√™ncias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Normaliza√ß√£o das Caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(videos_processados) > 0:\n",
    "    print(\"üîß Aplicando normaliza√ß√£o inteligente das caracter√≠sticas...\")\n",
    "    \n",
    "    # Usar RobustScaler para lidar melhor com outliers\n",
    "    scaler = RobustScaler()\n",
    "    \n",
    "    # Reorganizar para normaliza√ß√£o\n",
    "    n_amostras, tam_seq, n_caracteristicas = X_raw.shape\n",
    "    X_reorganizado = X_raw.reshape(-1, n_caracteristicas)\n",
    "    \n",
    "    # Aplicar e transformar\n",
    "    X_normalizado_flat = scaler.fit_transform(X_reorganizado)\n",
    "    X_normalizado = X_normalizado_flat.reshape(n_amostras, tam_seq, n_caracteristicas)\n",
    "    \n",
    "    print(f\"‚úÖ Normaliza√ß√£o das caracter√≠sticas conclu√≠da\")\n",
    "    \n",
    "    # Analisar caracter√≠sticas normalizadas\n",
    "    nomes_caracteristicas = ['PERCLOS', 'MAR', 'BLINK_RATE', 'HEAD_STABILITY']\n",
    "    print(f\"\\nüìä Faixas das Caracter√≠sticas Normalizadas:\")\n",
    "    for i, nome_caracteristica in enumerate(nomes_caracteristicas):\n",
    "        dados_caracteristica = X_normalizado[:, :, i].flatten()\n",
    "        print(f\"  {nome_caracteristica:15}: [{dados_caracteristica.min():6.2f}, {dados_caracteristica.max():6.2f}]\")\n",
    "        print(f\"                     Œº={dados_caracteristica.mean():6.3f}, œÉ={dados_caracteristica.std():6.3f}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ An√°lise da normaliza√ß√£o das caracter√≠sticas completa\")\n",
    "else:\n",
    "    print(\"‚ùå Nenhum dado dispon√≠vel para normaliza√ß√£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Configura√ß√£o de Valida√ß√£o Cruzada por Participante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(videos_processados) > 0:\n",
    "    print(\"üîÑ Criando divis√µes de valida√ß√£o cruzada por participante...\")\n",
    "    \n",
    "    participantes_unicos = np.unique(participantes)\n",
    "    n_participantes = len(participantes_unicos)\n",
    "    \n",
    "    print(f\"Total de participantes: {n_participantes}\")\n",
    "    \n",
    "    # Criar divis√µes de valida√ß√£o cruzada 5-fold\n",
    "    n_folds = min(5, n_participantes)\n",
    "    divisoes_cv = []\n",
    "    \n",
    "    if n_participantes >= 5:\n",
    "        # Valida√ß√£o cruzada 5-fold padr√£o\n",
    "        participantes_por_fold = n_participantes // n_folds\n",
    "        \n",
    "        for fold in range(n_folds):\n",
    "            # Participantes de teste\n",
    "            idx_inicio = fold * participantes_por_fold\n",
    "            idx_fim = idx_inicio + participantes_por_fold\n",
    "            if fold == n_folds - 1:  # √öltimo fold pega os restantes\n",
    "                idx_fim = n_participantes\n",
    "            \n",
    "            participantes_teste = participantes_unicos[idx_inicio:idx_fim]\n",
    "            participantes_restantes = np.setdiff1d(participantes_unicos, participantes_teste)\n",
    "            \n",
    "            # Dividir restantes em treino/valida√ß√£o\n",
    "            if len(participantes_restantes) >= 4:\n",
    "                participantes_treino, participantes_val = train_test_split(\n",
    "                    participantes_restantes, test_size=0.2, random_state=42\n",
    "                )\n",
    "            else:\n",
    "                participantes_treino = participantes_restantes\n",
    "                participantes_val = np.array([])\n",
    "            \n",
    "            # Criar m√°scaras\n",
    "            mascara_treino = np.isin(participantes, participantes_treino)\n",
    "            mascara_val = np.isin(participantes, participantes_val)\n",
    "            mascara_teste = np.isin(participantes, participantes_teste)\n",
    "            \n",
    "            divisoes_cv.append({\n",
    "                'fold': fold,\n",
    "                'train_subjects': participantes_treino,\n",
    "                'val_subjects': participantes_val,\n",
    "                'test_subjects': participantes_teste,\n",
    "                'train_mask': mascara_treino,\n",
    "                'val_mask': mascara_val,\n",
    "                'test_mask': mascara_teste\n",
    "            })\n",
    "            \n",
    "            print(f\"Fold {fold}: Treino({len(participantes_treino)}), Val({len(participantes_val)}), Teste({len(participantes_teste)})\")\n",
    "    \n",
    "    else:\n",
    "        # Divis√£o simples treino/teste para poucos participantes\n",
    "        tamanho_teste = max(1, n_participantes // 4)\n",
    "        participantes_treino, participantes_teste = train_test_split(\n",
    "            participantes_unicos, test_size=tamanho_teste, random_state=42\n",
    "        )\n",
    "        \n",
    "        mascara_treino = np.isin(participantes, participantes_treino)\n",
    "        mascara_teste = np.isin(participantes, participantes_teste)\n",
    "        \n",
    "        divisoes_cv.append({\n",
    "            'fold': 0,\n",
    "            'train_subjects': participantes_treino,\n",
    "            'val_subjects': np.array([]),\n",
    "            'test_subjects': participantes_teste,\n",
    "            'train_mask': mascara_treino,\n",
    "            'val_mask': np.zeros(len(participantes), dtype=bool),\n",
    "            'test_mask': mascara_teste\n",
    "        })\n",
    "        \n",
    "        print(f\"Divis√£o √∫nica: Treino({len(participantes_treino)}), Teste({len(participantes_teste)})\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Criadas {len(divisoes_cv)} divis√µes de valida√ß√£o cruzada\")\n",
    "else:\n",
    "    divisoes_cv = []\n",
    "    print(\"‚ùå Nenhum dado dispon√≠vel para configura√ß√£o CV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Salvar Dataset Processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(videos_processados) > 0:\n",
    "    # Criar diret√≥rio de sa√≠da\n",
    "    diretorio_saida = Path('/home/zhizhunu/tcc/ia-fadiga-main2/processed_data_uta_rldd_CORRECTED')\n",
    "    diretorio_saida.mkdir(exist_ok=True)\n",
    "\n",
    "    print(f\"üíæ Salvando dataset processado em {diretorio_saida}...\")\n",
    "\n",
    "    # Salvar arrays principais\n",
    "    np.save(diretorio_saida / 'X_sequences.npy', X_normalizado)\n",
    "    np.save(diretorio_saida / 'y_labels.npy', y)\n",
    "    np.save(diretorio_saida / 'subjects.npy', participantes)\n",
    "\n",
    "    print(f\"  ‚úÖ Arrays principais salvos: X{X_normalizado.shape}, y{y.shape}, subjects{participantes.shape}\")\n",
    "\n",
    "    # Salvar scaler\n",
    "    with open(diretorio_saida / 'feature_scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "    # Salvar divis√µes de valida√ß√£o cruzada\n",
    "    with open(diretorio_saida / 'cv_splits.pkl', 'wb') as f:\n",
    "        pickle.dump(divisoes_cv, f)\n",
    "\n",
    "    # Criar extrator tempor√°rio para valores de threshold\n",
    "    extrator_temp = ExtratorCaracteristicasFadiga()\n",
    "\n",
    "    # Salvar metadados\n",
    "    metadados = {\n",
    "        'dataset': 'UTA-RLDD-PROCESSADO',\n",
    "        'versao': '1.0',\n",
    "        'caracteristicas': nomes_caracteristicas,\n",
    "        'tamanho_sequencia': SEQUENCE_LENGTH,\n",
    "        'razao_sobreposicao': OVERLAP_RATIO,\n",
    "        'fps_alvo': TARGET_FPS,\n",
    "        'n_amostras': X_normalizado.shape[0],\n",
    "        'n_caracteristicas': X_normalizado.shape[2],\n",
    "        'n_participantes': len(participantes_unicos),\n",
    "        'n_folds': len(divisoes_cv),\n",
    "        'mapeamento_classes': {0: 'Alert', 5: 'Low_Vigilant', 10: 'Drowsy'},\n",
    "        'videos_processados': len(videos_processados),\n",
    "        'videos_falharam': len(videos_falharam),\n",
    "        'configuracoes_processamento': {\n",
    "            'modo_rapido': MODO_RAPIDO,\n",
    "            'max_videos_processados': MAX_VIDEOS,\n",
    "            'duracao_max_sec': DURACAO_MAX,\n",
    "            'pular_frames': PULAR_FRAMES,\n",
    "            'threshold_qualidade': THRESHOLD_QUALIDADE\n",
    "        },\n",
    "        'thresholds_caracteristicas': {\n",
    "            'EAR_FECHADO': extrator_temp.EAR_FECHADO_THRESHOLD,\n",
    "            'EAR_PISCADA': extrator_temp.EAR_PISCADA_THRESHOLD,\n",
    "            'MAR_BOCEJO': extrator_temp.MAR_BOCEJO_THRESHOLD\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(diretorio_saida / 'metadata.json', 'w') as f:\n",
    "        json.dump(metadados, f, indent=2)\n",
    "\n",
    "    # Salvar resultados do processamento\n",
    "    resultados = {\n",
    "        'videos_processados': [{\n",
    "            'filename': video['filename'],\n",
    "            'subject_id': video['subject_id'],\n",
    "            'state': video['state'],\n",
    "            'label': video['label'],\n",
    "            'n_frames': video['n_frames']\n",
    "        } for video in videos_processados],\n",
    "        'videos_falharam': videos_falharam,\n",
    "        'metricas_qualidade': {\n",
    "            'taxa_sucesso': len(videos_processados) / (len(videos_processados) + len(videos_falharam)),\n",
    "            'media_frames_por_video': np.mean([v['n_frames'] for v in videos_processados]),\n",
    "            'total_sequencias': len(X_normalizado)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(diretorio_saida / 'processing_results.json', 'w') as f:\n",
    "        json.dump(resultados, f, indent=2)\n",
    "\n",
    "    # Salvar an√°lise das caracter√≠sticas se dispon√≠vel\n",
    "    if 'df_caracteristicas' in locals():\n",
    "        # Amostrar os dados se muito grandes\n",
    "        if len(df_caracteristicas) > 100000:\n",
    "            amostra_df = df_caracteristicas.sample(n=100000, random_state=42)\n",
    "            amostra_df.to_csv(diretorio_saida / 'feature_analysis_sample.csv', index=False)\n",
    "        else:\n",
    "            df_caracteristicas.to_csv(diretorio_saida / 'feature_analysis.csv', index=False)\n",
    "\n",
    "    # Resumo\n",
    "    print(f\"\\nüìÅ Arquivos salvos:\")\n",
    "    for caminho_arquivo in sorted(diretorio_saida.glob('*')):\n",
    "        if caminho_arquivo.is_file():\n",
    "            tamanho_mb = caminho_arquivo.stat().st_size / (1024 * 1024)\n",
    "            print(f\"  - {caminho_arquivo.name}: {tamanho_mb:.2f} MB\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Dataset processado salvo com sucesso!\")\n",
    "else:\n",
    "    print(\"‚ùå Nenhum dado para salvar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üéâ PREPARA√á√ÉO DOS DADOS UTA-RLDD - RESUMO FINAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(videos_processados) > 0:\n",
    "    print(f\"\\n‚úÖ SUCESSO: Dataset de detec√ß√£o de fadiga de alta qualidade criado!\")\n",
    "    print(f\"\\nüìä Estat√≠sticas do Dataset:\")\n",
    "    print(f\"  ‚Ä¢ V√≠deos processados: {len(videos_processados)}/{len(df_videos)} ({len(videos_processados)/len(df_videos)*100:.1f}%)\")\n",
    "    print(f\"  ‚Ä¢ Total de sequ√™ncias: {X_normalizado.shape[0]:,}\")\n",
    "    print(f\"  ‚Ä¢ Comprimento da sequ√™ncia: {X_normalizado.shape[1]} frames ({X_normalizado.shape[1]/TARGET_FPS:.1f} segundos)\")\n",
    "    print(f\"  ‚Ä¢ Caracter√≠sticas: {X_normalizado.shape[2]} ({', '.join(nomes_caracteristicas)})\")\n",
    "    print(f\"  ‚Ä¢ Participantes: {len(participantes_unicos)}\")\n",
    "    print(f\"  ‚Ä¢ Folds de valida√ß√£o cruzada: {len(divisoes_cv)}\")\n",
    "    \n",
    "    # Distribui√ß√£o de classes\n",
    "    print(f\"\\nüéØ Distribui√ß√£o de Classes:\")\n",
    "    labels_unicos, contagens = np.unique(y, return_counts=True)\n",
    "    for label, contagem in zip(labels_unicos, contagens):\n",
    "        nome_estado = {0: 'Alert', 5: 'Low_Vigilant', 10: 'Drowsy'}[label]\n",
    "        percentual = contagem / len(y) * 100\n",
    "        print(f\"  ‚Ä¢ {nome_estado:12}: {contagem:6,} sequ√™ncias ({percentual:5.1f}%)\")\n",
    "    \n",
    "    # Performance esperada\n",
    "    print(f\"\\nüöÄ Performance Esperada do Modelo:\")\n",
    "    print(f\"  ‚Ä¢ Precis√£o alvo: 75-85%\")\n",
    "    print(f\"  ‚Ä¢ Caracter√≠sticas com din√¢mica temporal adequada\")\n",
    "    print(f\"  ‚Ä¢ Poder discriminativo aprimorado entre classes\")\n",
    "    print(f\"  ‚Ä¢ Valida√ß√£o cruzada real√≠stica por participante\")\n",
    "    \n",
    "    print(f\"\\nüìÇ Diret√≥rio de Sa√≠da:\")\n",
    "    print(f\"  {diretorio_saida}\")\n",
    "    \n",
    "    print(f\"\\nüîÑ Pr√≥ximos Passos:\")\n",
    "    print(f\"  1. ‚úÖ Dataset processado com caracter√≠sticas otimizadas\")\n",
    "    print(f\"  2. üöÄ Treinar modelo TCN com dataset processado\")\n",
    "    print(f\"  3. üìà Comparar performance com resultados anteriores\")\n",
    "    print(f\"  4. üéØ Atingir meta de precis√£o de 75-85%\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n‚ùå FALHOU: Nenhum v√≠deo foi processado com sucesso\")\n",
    "    print(f\"\\nüîß Solu√ß√£o de problemas:\")\n",
    "    print(f\"  ‚Ä¢ Verificar acessibilidade e formatos dos arquivos de v√≠deo\")\n",
    "    print(f\"  ‚Ä¢ Verificar instala√ß√£o do MediaPipe\")\n",
    "    print(f\"  ‚Ä¢ Revisar mensagens de erro dos v√≠deos que falharam\")\n",
    "    \n",
    "    if len(videos_falharam) > 0:\n",
    "        print(f\"\\n‚ùå V√≠deos que Falharam ({len(videos_falharam)}):\")\n",
    "        for i, falha in enumerate(videos_falharam[:5]):\n",
    "            print(f\"  {i+1}. {Path(falha['video_path']).name}: {falha['error']}\")\n",
    "        if len(videos_falharam) > 5:\n",
    "            print(f\"  ... e mais {len(videos_falharam)-5}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
