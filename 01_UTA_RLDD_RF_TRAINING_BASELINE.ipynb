{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento Random Forest - Baseline UTA-RLDD\n",
    "\n",
    "Este notebook implementa um modelo baseline usando Random Forest para detecção de fadiga no dataset UTA-RLDD.\n",
    "\n",
    "**Pré-requisito**: Execute o notebook de preparação de dados primeiro.\n",
    "\n",
    "**Meta**: Atingir 75-85% de acurácia como baseline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas principais\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, \n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Análise estatística\n",
    "from scipy import stats\n",
    "\n",
    "print(\"Bibliotecas carregadas com sucesso!\")\n",
    "print(f\"Diretório atual: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos dos dados\n",
    "DIRETORIO_DADOS = Path(\"processed_data_uta_rldd_CORRECTED\")\n",
    "DIRETORIO_MODELOS = DIRETORIO_DADOS / \"rf_models\"\n",
    "DIRETORIO_MODELOS.mkdir(exist_ok=True)\n",
    "\n",
    "# Nomes das características originais\n",
    "NOMES_SINAIS = ['PERCLOS', 'MAR', 'BLINK_RATE', 'HEAD_STABILITY']\n",
    "NOMES_STATS = ['mean', 'std', 'median', 'min', 'max', 'range', 'q25', 'q75', 'trend', 'zcr', 'autocorr']\n",
    "\n",
    "# Criar nomes das features\n",
    "NOMES_FEATURES = []\n",
    "for sinal in NOMES_SINAIS:\n",
    "    for stat in NOMES_STATS:\n",
    "        NOMES_FEATURES.append(f\"{sinal}_{stat}\")\n",
    "\n",
    "print(f\"Total de features a extrair: {len(NOMES_FEATURES)}\")\n",
    "print(f\"Diretório dos dados: {DIRETORIO_DADOS}\")\n",
    "print(f\"Diretório dos modelos: {DIRETORIO_MODELOS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_dados_processados():\n",
    "    \"\"\"Carrega sequências e labels do notebook de preparação de dados\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Tentar carregar arquivos numpy\n",
    "        arquivo_X = DIRETORIO_DADOS / \"X_sequences.npy\"\n",
    "        arquivo_y = DIRETORIO_DADOS / \"y_labels.npy\"\n",
    "        \n",
    "        if arquivo_X.exists() and arquivo_y.exists():\n",
    "            X_sequences = np.load(arquivo_X)\n",
    "            y_labels = np.load(arquivo_y)\n",
    "            print(f\"Dados carregados de {arquivo_X} e {arquivo_y}\")\n",
    "            return {'X_sequences': X_sequences, 'y_labels': y_labels}\n",
    "        \n",
    "        # Listar arquivos disponíveis\n",
    "        arquivos_disponiveis = list(DIRETORIO_DADOS.glob(\"*.pkl\")) + list(DIRETORIO_DADOS.glob(\"*.npy\"))\n",
    "        print(f\"Arquivos disponíveis em {DIRETORIO_DADOS}:\")\n",
    "        for arquivo in arquivos_disponiveis:\n",
    "            print(f\"  - {arquivo.name}\")\n",
    "        \n",
    "        raise FileNotFoundError(\"Não foi possível encontrar os dados processados\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar dados: {e}\")\n",
    "        print(\"Execute o notebook de preparação de dados primeiro.\")\n",
    "        raise\n",
    "\n",
    "# Carregar os dados\n",
    "dados = carregar_dados_processados()\n",
    "\n",
    "X_sequences = dados['X_sequences']\n",
    "y_labels = dados['y_labels']\n",
    "\n",
    "print(f\"Formato das sequências: {X_sequences.shape}\")\n",
    "print(f\"Formato dos labels: {y_labels.shape}\")\n",
    "print(f\"Labels únicos: {np.unique(y_labels)}\")\n",
    "print(f\"Distribuição dos labels: {np.bincount(y_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extração de Características Estatísticas\n",
    "\n",
    "Converte sequências temporais (90 frames × 4 features) em características estatísticas para ML clássico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtratorCaracteristicasFadiga:\n",
    "    \"\"\"Extrai características estatísticas de sequências temporais para ML clássico\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.nomes_features = NOMES_FEATURES.copy()\n",
    "    \n",
    "    def inclinacao_tendencia(self, sinal):\n",
    "        \"\"\"Calcula inclinação da tendência linear\"\"\"\n",
    "        if len(sinal) < 2:\n",
    "            return 0.0\n",
    "        x = np.arange(len(sinal))\n",
    "        try:\n",
    "            inclinacao, _, _, _, _ = stats.linregress(x, sinal)\n",
    "            return inclinacao if not np.isnan(inclinacao) else 0.0\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def taxa_cruzamento_zero(self, sinal):\n",
    "        \"\"\"Taxa de cruzamento do zero (medida de variabilidade)\"\"\"\n",
    "        if len(sinal) < 2:\n",
    "            return 0.0\n",
    "        centrado_na_media = sinal - np.mean(sinal)\n",
    "        cruzamentos = np.sum(np.diff(np.sign(centrado_na_media)) != 0)\n",
    "        return cruzamentos / len(sinal)\n",
    "    \n",
    "    def autocorr_lag1(self, sinal):\n",
    "        \"\"\"Autocorrelação de lag-1 (consistência temporal)\"\"\"\n",
    "        if len(sinal) < 3:\n",
    "            return 0.0\n",
    "        try:\n",
    "            corr = np.corrcoef(sinal[:-1], sinal[1:])[0, 1]\n",
    "            return corr if not np.isnan(corr) else 0.0\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def extrair_features_sinal(self, sinal):\n",
    "        \"\"\"Extrai 11 características estatísticas de um único sinal\"\"\"\n",
    "        features = [\n",
    "            np.mean(sinal),                    # Tendência central\n",
    "            np.std(sinal),                     # Variabilidade  \n",
    "            np.median(sinal),                  # Tendência central robusta\n",
    "            np.min(sinal),                     # Medidas de amplitude\n",
    "            np.max(sinal),\n",
    "            np.ptp(sinal),                     # Peak-to-peak (max - min)\n",
    "            np.percentile(sinal, 25),          # Quartis da distribuição\n",
    "            np.percentile(sinal, 75),\n",
    "            self.inclinacao_tendencia(sinal), # Dinâmica temporal\n",
    "            self.taxa_cruzamento_zero(sinal),\n",
    "            self.autocorr_lag1(sinal)          # Correlação temporal\n",
    "        ]\n",
    "        return features\n",
    "    \n",
    "    def transform(self, X_sequences):\n",
    "        \"\"\"\n",
    "        Transforma sequências temporais em características estatísticas\n",
    "        \n",
    "        Input: (n_samples, 90, 4) - sequências temporais\n",
    "        Output: (n_samples, 44) - características estatísticas\n",
    "        \"\"\"\n",
    "        n_samples = X_sequences.shape[0]\n",
    "        n_features = len(self.nomes_features)\n",
    "        \n",
    "        X_features = np.zeros((n_samples, n_features))\n",
    "        \n",
    "        print(f\"Extraindo características para {n_samples} sequências...\")\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"  Processando amostra {i}/{n_samples}\")\n",
    "            \n",
    "            sequencia = X_sequences[i]  # Shape: (90, 4)\n",
    "            features_amostra = []\n",
    "            \n",
    "            # Extrair features para cada um dos 4 sinais\n",
    "            for idx_sinal in range(4):  # PERCLOS, MAR, BLINK_RATE, HEAD_STABILITY\n",
    "                sinal = sequencia[:, idx_sinal]\n",
    "                features_sinal = self.extrair_features_sinal(sinal)\n",
    "                features_amostra.extend(features_sinal)\n",
    "            \n",
    "            X_features[i] = features_amostra\n",
    "        \n",
    "        print(f\"Extração de características concluída! Shape: {X_features.shape}\")\n",
    "        return X_features\n",
    "\n",
    "# Inicializar extrator\n",
    "extrator_features = ExtratorCaracteristicasFadiga()\n",
    "print(f\"Extrator inicializado com {len(extrator_features.nomes_features)} características\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extrair Características das Sequências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair características estatísticas das sequências temporais\n",
    "print(\"Extraindo características estatísticas das sequências temporais...\")\n",
    "print(f\"Formato de entrada: {X_sequences.shape} (amostras, passos_temporais, características)\")\n",
    "\n",
    "X_features = extrator_features.transform(X_sequences)\n",
    "\n",
    "print(f\"\\nResultados da extração:\")\n",
    "print(f\"  Sequências originais: {X_sequences.shape}\")\n",
    "print(f\"  Características extraídas: {X_features.shape}\")\n",
    "print(f\"  Features por sinal: 11\")\n",
    "print(f\"  Total de sinais: 4 (PERCLOS, MAR, BLINK_RATE, HEAD_STABILITY)\")\n",
    "\n",
    "# Verificar qualidade dos dados\n",
    "nan_count = np.isnan(X_features).sum()\n",
    "inf_count = np.isinf(X_features).sum()\n",
    "print(f\"\\nVerificação de qualidade:\")\n",
    "print(f\"  Valores NaN: {nan_count}\")\n",
    "print(f\"  Valores infinitos: {inf_count}\")\n",
    "\n",
    "if nan_count > 0 or inf_count > 0:\n",
    "    print(\"  Corrigindo valores NaN/Inf...\")\n",
    "    X_features = np.nan_to_num(X_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(\"\\nEstatísticas das características:\")\n",
    "print(f\"  Média: {np.mean(X_features):.4f}\")\n",
    "print(f\"  Desvio padrão: {np.std(X_features):.4f}\")\n",
    "print(f\"  Min: {np.min(X_features):.4f}\")\n",
    "print(f\"  Max: {np.max(X_features):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Divisão e Pré-processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados mantendo balanceamento das classes\n",
    "print(\"Dividindo dados em conjuntos de treino/teste...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_features, y_labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_labels\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"Conjunto de teste: {X_test.shape[0]} amostras\")\n",
    "print(f\"Distribuição treino: {np.bincount(y_train)}\")\n",
    "print(f\"Distribuição teste: {np.bincount(y_test)}\")\n",
    "\n",
    "# Normalização das características\n",
    "print(\"\\nAplicando normalização...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Dados de treino normalizados: {X_train_scaled.shape}\")\n",
    "print(f\"Dados de teste normalizados: {X_test_scaled.shape}\")\n",
    "\n",
    "# Verificar normalização\n",
    "print(f\"\\nEstatísticas após normalização (treino):\")\n",
    "print(f\"  Média: {np.mean(X_train_scaled):.6f}\")\n",
    "print(f\"  Desvio padrão: {np.std(X_train_scaled):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Treinamento do Modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar Random Forest baseline\n",
    "print(\"Treinando classificador Random Forest baseline...\")\n",
    "\n",
    "rf_baseline = RandomForestClassifier(\n",
    "    n_estimators=100,           # 100 árvores\n",
    "    max_depth=10,               # Evitar overfitting\n",
    "    min_samples_split=5,        # Evitar overfitting\n",
    "    min_samples_leaf=2,         # Evitar overfitting\n",
    "    class_weight='balanced',    # Lidar com desbalanceamento\n",
    "    random_state=42,            # Reprodutibilidade\n",
    "    n_jobs=-1                   # Usar todos os cores\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "rf_baseline.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Treinamento Random Forest concluído!\")\n",
    "print(f\"Número de características usadas: {rf_baseline.n_features_in_}\")\n",
    "print(f\"Número de árvores: {rf_baseline.n_estimators}\")\n",
    "print(f\"Classes: {rf_baseline.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer predições\n",
    "print(\"Avaliando modelo Random Forest baseline...\")\n",
    "\n",
    "y_train_pred = rf_baseline.predict(X_train_scaled)\n",
    "y_test_pred = rf_baseline.predict(X_test_scaled)\n",
    "y_test_proba = rf_baseline.predict_proba(X_test_scaled)\n",
    "\n",
    "# Calcular métricas\n",
    "acuracia_treino = accuracy_score(y_train, y_train_pred)\n",
    "acuracia_teste = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Determinar nomes das classes\n",
    "classes_unicas = np.unique(y_test)\n",
    "print(f\"Classes detectadas: {classes_unicas}\")\n",
    "\n",
    "# Mapear labels para nomes\n",
    "mapeamento_classes = {0: 'Alert', 5: 'Low_Vigilant', 10: 'Drowsy'}\n",
    "nomes_classes = [mapeamento_classes.get(cls, f'Classe_{cls}') for cls in sorted(classes_unicas)]\n",
    "\n",
    "print(f\"\\n=== RESULTADOS BASELINE ===\")\n",
    "print(f\"Acurácia Treino: {acuracia_treino:.4f} ({acuracia_treino*100:.2f}%)\")\n",
    "print(f\"Acurácia Teste: {acuracia_teste:.4f} ({acuracia_teste*100:.2f}%)\")\n",
    "print(f\"Tipo do problema: {len(classes_unicas)}-classe\")\n",
    "print(f\"Classes: {nomes_classes}\")\n",
    "\n",
    "# Relatório detalhado\n",
    "print(f\"\\n=== RELATÓRIO DETALHADO ===\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=nomes_classes))\n",
    "\n",
    "# Matriz de confusão\n",
    "print(f\"\\n=== MATRIZ DE CONFUSÃO ===\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm)\n",
    "print(f\"Linhas: Labels verdadeiros, Colunas: Predições\")\n",
    "print(f\"Ordem das classes: {nomes_classes}\")\n",
    "\n",
    "# ROC AUC\n",
    "try:\n",
    "    if len(classes_unicas) == 2:\n",
    "        roc_auc = roc_auc_score(y_test, y_test_proba[:, 1])\n",
    "        print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n",
    "    else:\n",
    "        roc_auc = roc_auc_score(y_test, y_test_proba, multi_class='ovr', average='macro')\n",
    "        print(f\"\\nROC AUC Score (macro-avg): {roc_auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nROC AUC: Não foi possível calcular - {str(e)}\")\n",
    "\n",
    "# Avaliação de performance\n",
    "print(f\"\\n=== AVALIAÇÃO DE PERFORMANCE ===\")\n",
    "if acuracia_teste >= 0.85:\n",
    "    print(\"🟢 EXCELENTE: Performance de nível clínico (≥85%)\")\n",
    "elif acuracia_teste >= 0.80:\n",
    "    print(\"🟡 MUITO BOM: Performance de alta qualidade (≥80%)\")\n",
    "elif acuracia_teste >= 0.75:\n",
    "    print(\"🔵 BOM: Performance aceitável (≥75%)\")\n",
    "elif acuracia_teste >= 0.70:\n",
    "    print(\"🟡 RAZOÁVEL: Performance mínima aceitável (≥70%)\")\n",
    "else:\n",
    "    print(\"🔴 RUIM: Abaixo da performance aceitável (<70%)\")\n",
    "\n",
    "print(f\"Meta: 75-85% de acurácia para uso clínico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Análise de Importância das Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de importância das características\n",
    "print(\"Analisando importância das características...\")\n",
    "\n",
    "# Obter importância das características do Random Forest\n",
    "scores_importancia = rf_baseline.feature_importances_\n",
    "df_importancia = pd.DataFrame({\n",
    "    'caracteristica': extrator_features.nomes_features,\n",
    "    'importancia': scores_importancia\n",
    "}).sort_values('importancia', ascending=False)\n",
    "\n",
    "# Mostrar top 20 características mais importantes\n",
    "print(f\"\\n=== TOP 20 CARACTERÍSTICAS MAIS IMPORTANTES ===\")\n",
    "print(df_importancia.head(20).to_string(index=False))\n",
    "\n",
    "# Agrupar por tipo de sinal\n",
    "importancia_por_sinal = {}\n",
    "for sinal in NOMES_SINAIS:\n",
    "    features_sinal = df_importancia[df_importancia['caracteristica'].str.startswith(sinal)]\n",
    "    importancia_por_sinal[sinal] = features_sinal['importancia'].sum()\n",
    "\n",
    "print(f\"\\n=== IMPORTÂNCIA POR TIPO DE SINAL ===\")\n",
    "for sinal, importancia in sorted(importancia_por_sinal.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{sinal:15} {importancia:.4f} ({importancia*100:.2f}%)\")\n",
    "\n",
    "# Visualizar importância das características\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Top 15 características\n",
    "top_features = df_importancia.head(15)\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.barh(range(len(top_features)), top_features['importancia'])\n",
    "plt.yticks(range(len(top_features)), top_features['caracteristica'])\n",
    "plt.xlabel('Importância da Característica')\n",
    "plt.title('Top 15 Características Mais Importantes')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Importância por sinal\n",
    "plt.subplot(2, 1, 2)\n",
    "sinais = list(importancia_por_sinal.keys())\n",
    "importancias = list(importancia_por_sinal.values())\n",
    "plt.bar(sinais, importancias)\n",
    "plt.xlabel('Tipo de Sinal')\n",
    "plt.ylabel('Importância Total')\n",
    "plt.title('Importância das Características por Tipo de Sinal')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Salvar importância das características\n",
    "df_importancia.to_csv(DIRETORIO_MODELOS / 'importancia_caracteristicas.csv', index=False)\n",
    "print(f\"\\nImportância das características salva em: {DIRETORIO_MODELOS / 'importancia_caracteristicas.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Validação Cruzada Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validação cruzada temporal para avaliar estabilidade\n",
    "print(\"Executando validação cruzada temporal...\")\n",
    "\n",
    "# Usar TimeSeriesSplit para respeitar ordem temporal\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Scores de validação cruzada\n",
    "cv_scores = cross_val_score(\n",
    "    rf_baseline, X_train_scaled, y_train, \n",
    "    cv=tscv, scoring='accuracy', n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\n=== RESULTADOS DA VALIDAÇÃO CRUZADA TEMPORAL ===\")\n",
    "print(f\"Scores individuais: {cv_scores}\")\n",
    "print(f\"Score médio: {cv_scores.mean():.4f} ({cv_scores.mean()*100:.2f}%)\")\n",
    "print(f\"Desvio padrão: {cv_scores.std():.4f} (±{cv_scores.std()*100:.2f}%)\")\n",
    "print(f\"Intervalo de confiança 95%: [{cv_scores.mean() - 2*cv_scores.std():.4f}, {cv_scores.mean() + 2*cv_scores.std():.4f}]\")\n",
    "\n",
    "# Avaliação de estabilidade\n",
    "if cv_scores.std() < 0.05:\n",
    "    print(\"\\n🟢 ESTÁVEL: Baixa variância entre folds (<5%)\")\n",
    "elif cv_scores.std() < 0.10:\n",
    "    print(\"\\n🟡 MODERADO: Variância aceitável entre folds (<10%)\")\n",
    "else:\n",
    "    print(\"\\n🔴 INSTÁVEL: Alta variância entre folds (≥10%)\")\n",
    "\n",
    "# Plotar resultados da validação cruzada\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(cv_scores) + 1), cv_scores, 'bo-', linewidth=2, markersize=8)\n",
    "plt.axhline(y=cv_scores.mean(), color='r', linestyle='--', label=f'Média: {cv_scores.mean():.3f}')\n",
    "plt.fill_between(range(1, len(cv_scores) + 1), \n",
    "                 cv_scores.mean() - cv_scores.std(), \n",
    "                 cv_scores.mean() + cv_scores.std(), \n",
    "                 alpha=0.2, color='red')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.title('Scores da Validação Cruzada')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(cv_scores, bins=5, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(cv_scores.mean(), color='red', linestyle='--', linewidth=2, label=f'Média: {cv_scores.mean():.3f}')\n",
    "plt.xlabel('Acurácia')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Distribuição dos Scores CV')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Salvar Modelo Treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar modelos treinados e componentes de pré-processamento\n",
    "print(\"Salvando modelos treinados e componentes...\")\n",
    "\n",
    "# Salvar modelo Random Forest baseline\n",
    "caminho_modelo_rf = DIRETORIO_MODELOS / 'rf_baseline_model.joblib'\n",
    "joblib.dump(rf_baseline, caminho_modelo_rf)\n",
    "print(f\"Random Forest baseline salvo em: {caminho_modelo_rf}\")\n",
    "\n",
    "# Salvar o scaler\n",
    "caminho_scaler = DIRETORIO_MODELOS / 'feature_scaler.joblib'\n",
    "joblib.dump(scaler, caminho_scaler)\n",
    "print(f\"Scaler salvo em: {caminho_scaler}\")\n",
    "\n",
    "# Salvar extrator de características\n",
    "caminho_extrator = DIRETORIO_MODELOS / 'feature_extractor.joblib'\n",
    "joblib.dump(extrator_features, caminho_extrator)\n",
    "print(f\"Extrator de características salvo em: {caminho_extrator}\")\n",
    "\n",
    "# Salvar informações das classes\n",
    "info_classes = {\n",
    "    'classes': rf_baseline.classes_.tolist(),\n",
    "    'n_classes': len(rf_baseline.classes_),\n",
    "    'mapeamento_classes': {0: 'Alert', 5: 'Low_Vigilant', 10: 'Drowsy'}\n",
    "}\n",
    "import json\n",
    "caminho_info_classes = DIRETORIO_MODELOS / 'class_info.json'\n",
    "with open(caminho_info_classes, 'w') as f:\n",
    "    json.dump(info_classes, f, indent=2)\n",
    "print(f\"Informações das classes salvas em: {caminho_info_classes}\")\n",
    "\n",
    "# Código para pipeline de deploy\n",
    "codigo_deploy = '''import joblib\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class PipelinePredicaoFadiga:\n",
    "    \"\"\"Pipeline completo para predição de fadiga usando Random Forest\"\"\"\n",
    "    \n",
    "    def __init__(self, diretorio_modelo):\n",
    "        diretorio_modelo = Path(diretorio_modelo)\n",
    "        \n",
    "        # Carregar componentes\n",
    "        self.extrator_features = joblib.load(diretorio_modelo / 'feature_extractor.joblib')\n",
    "        self.scaler = joblib.load(diretorio_modelo / 'feature_scaler.joblib')\n",
    "        self.classificador = joblib.load(diretorio_modelo / 'rf_baseline_model.joblib')\n",
    "        \n",
    "        # Carregar informações das classes\n",
    "        with open(diretorio_modelo / 'class_info.json', 'r') as f:\n",
    "            self.info_classes = json.load(f)\n",
    "        \n",
    "        self.classes = self.info_classes['classes']\n",
    "        self.mapeamento_classes = self.info_classes['mapeamento_classes']\n",
    "    \n",
    "    def predizer_sequencia(self, sequencia):\n",
    "        \"\"\"Prediz fadiga de uma única sequência de 90 frames\"\"\"\n",
    "        # Adicionar dimensão de batch\n",
    "        sequencias = np.expand_dims(sequencia, axis=0)\n",
    "        \n",
    "        # Extrair características\n",
    "        features = self.extrator_features.transform(sequencias)\n",
    "        \n",
    "        # Normalizar características\n",
    "        features_normalizadas = self.scaler.transform(features)\n",
    "        \n",
    "        # Fazer predição\n",
    "        predicao = self.classificador.predict(features_normalizadas)[0]\n",
    "        probabilidades_array = self.classificador.predict_proba(features_normalizadas)[0]\n",
    "        \n",
    "        # Criar dicionário de probabilidades\n",
    "        probabilidades = {}\n",
    "        for i, label_classe in enumerate(self.classes):\n",
    "            nome_classe = self.mapeamento_classes.get(str(label_classe), f'Classe_{label_classe}')\n",
    "            probabilidades[nome_classe] = float(probabilidades_array[i])\n",
    "        \n",
    "        # Obter nome da classe predita\n",
    "        nome_classe_predita = self.mapeamento_classes.get(str(predicao), f'Classe_{predicao}')\n",
    "        \n",
    "        return predicao, probabilidades, nome_classe_predita\n",
    "\n",
    "# Exemplo de uso:\n",
    "# pipeline = PipelinePredicaoFadiga('processed_data_uta_rldd_CORRECTED/rf_models')\n",
    "# predicao, probabilidades, nome_classe = pipeline.predizer_sequencia(dados_sequencia)\n",
    "# print(f\"Predição: {nome_classe} (label: {predicao})\")\n",
    "# print(f\"Probabilidades: {probabilidades}\")\n",
    "'''\n",
    "\n",
    "# Salvar código de deploy\n",
    "caminho_deploy = DIRETORIO_MODELOS / 'pipeline_deploy.py'\n",
    "with open(caminho_deploy, 'w') as f:\n",
    "    f.write(codigo_deploy)\n",
    "print(f\"Pipeline de deploy salvo em: {caminho_deploy}\")\n",
    "\n",
    "print(f\"\\n=== TREINAMENTO CONCLUÍDO COM SUCESSO ===\")\n",
    "print(f\"✅ Modelo Random Forest treinado e salvo\")\n",
    "print(f\"✅ Pipeline de extração de características salvo\")\n",
    "print(f\"✅ Componentes de pré-processamento salvos\")\n",
    "print(f\"✅ Informações das classes salvas\")\n",
    "print(f\"✅ Código de deploy gerado\")\n",
    "print(f\"✅ Performance do modelo: {acuracia_teste:.1%}\")\n",
    "print(f\"\\nLocalização dos arquivos: {DIRETORIO_MODELOS}\")\n",
    "print(f\"\\nModelo suporta classificação de {len(rf_baseline.classes_)} classes:\")\n",
    "for cls in rf_baseline.classes_:\n",
    "    nome_classe = mapeamento_classes.get(cls, f'Classe_{cls}')\n",
    "    print(f\"  - Classe {cls}: {nome_classe}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
